# ğŸ”— IntegraÃ§Ã£o LangChain - DeepSeek & OpLab

**ğŸ“‹ Tipo:** Guia de IntegraÃ§Ã£o TÃ©cnica  
**ğŸ¯ Foco:** LangChain + DeepSeek + OpLab  
**ğŸ“Š Status:** âœ… **IMPLEMENTADO**

---

## ğŸ“‹ Resumo Executivo

Esta implementaÃ§Ã£o fornece uma integraÃ§Ã£o robusta e escalÃ¡vel entre as APIs DeepSeek e OpLab usando LangChain como framework de orquestraÃ§Ã£o. A soluÃ§Ã£o oferece:

- âœ… **AutenticaÃ§Ã£o adequada** para ambas as APIs
- âœ… **Captura completa** de dados da API OpLab
- âœ… **Processamento inteligente** via DeepSeek AI
- âœ… **Tratamento de erros** e retry automÃ¡tico
- âœ… **Logging detalhado** para monitoramento
- âœ… **Rate limiting** para evitar throttling
- âœ… **Pipeline assÃ­ncrono** para melhor performance
- âœ… **ValidaÃ§Ã£o de dados** em todas as etapas
- âœ… **Cache inteligente** para otimizaÃ§Ã£o

---

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

### ğŸ“Š Componentes Principais

```mermaid
graph TD
    A[Client Request] --> B[API Endpoint /api/chat/langchain]
    B --> C[LangChain Integration Service]
    C --> D[OpLab Tool]
    C --> E[DeepSeek Tool]
    D --> F[OpLab API]
    E --> G[DeepSeek API]
    
    B --> H[Authentication]
    B --> I[Validation]
    B --> J[Rate Limiting]
    
    C --> K[Smart Routing]
    C --> L[Tool Orchestration]
    C --> M[Cache Management]
    C --> N[Retry Logic]
```

### ğŸ”„ Fluxo de Processamento

1. **ğŸ“¨ Recebimento da RequisiÃ§Ã£o**
   - AutenticaÃ§Ã£o do usuÃ¡rio
   - ValidaÃ§Ã£o dos dados de entrada
   - VerificaÃ§Ã£o de rate limiting

2. **ğŸ§  Roteamento Inteligente**
   - AnÃ¡lise da mensagem
   - DecisÃ£o sobre ferramentas a usar
   - PreparaÃ§Ã£o do contexto

3. **âš¡ ExecuÃ§Ã£o das Ferramentas**
   - OpLab para dados de mercado
   - DeepSeek para anÃ¡lise e explicaÃ§Ãµes
   - Tratamento de erros e retry

4. **ğŸ“‹ ConsolidaÃ§Ã£o da Resposta**
   - CombinaÃ§Ã£o de resultados
   - FormataÃ§Ã£o da resposta final
   - Cache para futuras consultas

---

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. ğŸ“¦ DependÃªncias

```bash
# Instalar dependÃªncias LangChain
npm install @langchain/core @langchain/community langchain ioredis --legacy-peer-deps

# Verificar instalaÃ§Ã£o
npm ls @langchain/core
```

### 2. ğŸ” VariÃ¡veis de Ambiente

```bash
# Adicionar ao .env.local
DEEPSEEK_API_KEY=your_deepseek_key_here
NEXT_PUBLIC_DEEPSEEK_BASE_URL=https://api.deepseek.com
OPLAB_ACCESS_TOKEN=your_oplab_token_here
OPLAB_BASE_URL=https://api.oplab.com.br/v3
REDIS_URL=redis://localhost:6379
```

### 3. ğŸ—„ï¸ ConfiguraÃ§Ã£o do Redis

#### **Desenvolvimento Local:**

```bash
# Instalar Redis
brew install redis

# Iniciar Redis
redis-server

# Verificar conexÃ£o
redis-cli ping
```

#### **ProduÃ§Ã£o:**

- **Redis Cloud**: https://redis.com/cloud/
- **AWS ElastiCache**: https://aws.amazon.com/elasticache/
- **Vercel KV**: https://vercel.com/storage/kv

### 4. ğŸš€ ConfiguraÃ§Ã£o de ProduÃ§Ã£o

```bash
# Vercel
vercel env add DEEPSEEK_API_KEY
vercel env add OPLAB_ACCESS_TOKEN
vercel env add REDIS_URL

# Netlify
netlify env:set DEEPSEEK_API_KEY your_key
netlify env:set OPLAB_ACCESS_TOKEN your_token
netlify env:set REDIS_URL your_redis_url
```

---

## ğŸš€ Uso PrÃ¡tico

### 1. ğŸ“¨ RequisiÃ§Ã£o BÃ¡sica

```javascript
const response = await fetch('/api/chat/langchain', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
  },
  body: JSON.stringify({
    message: '/market-status',
    userId: 'user_123',
    options: {
      enableCache: true,
      temperature: 0.3,
    },
  }),
});

const result = await response.json();
console.log(result.response);
```

### 2. ğŸ¯ Casos de Uso EspecÃ­ficos

#### ğŸ“ˆ Consulta OpLab Direta

```javascript
{
  "message": "/market-status",
  "userId": "user_123",
  "options": {
    "enableCache": true,
    "temperature": 0.1
  }
}
```

#### ğŸ¤– AnÃ¡lise com DeepSeek

```javascript
{
  "message": "Explique como funciona a estratÃ©gia de covered call",
  "userId": "user_123",
  "options": {
    "temperature": 0.5,
    "maxTokens": 1500
  }
}
```

#### ğŸ”„ Consulta HÃ­brida (OpLab + DeepSeek)

```javascript
{
  "message": "Analise as opÃ§Ãµes da PETR4 e sugira uma estratÃ©gia",
  "userId": "user_123",
  "includeMarketData": true,
  "options": {
    "temperature": 0.3,
    "enableCache": true
  }
}
```

---

## ğŸ”§ ImplementaÃ§Ã£o TÃ©cnica

### ğŸ“ Estrutura de Arquivos

```
src/
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ langchain-integration.ts
â”œâ”€â”€ app/
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ chat/
â”‚           â””â”€â”€ langchain/
â”‚               â””â”€â”€ route.ts
â””â”€â”€ types/
    â””â”€â”€ langchain.ts
```

### ğŸ› ï¸ ConfiguraÃ§Ã£o Principal

```typescript
// src/lib/services/langchain-integration.ts
import { ChatDeepSeek } from '@langchain/community/chat_models/deepseek';
import { Tool } from '@langchain/core/tools';
import { AgentExecutor, createReactAgent } from 'langchain/agents';

export class LangChainIntegrationService {
  private deepSeekModel: ChatDeepSeek;
  private tools: Tool[];
  private agent: AgentExecutor;

  constructor() {
    this.initializeModels();
    this.initializeTools();
    this.createAgent();
  }

  private initializeModels() {
    this.deepSeekModel = new ChatDeepSeek({
      apiKey: process.env.DEEPSEEK_API_KEY,
      baseURL: process.env.NEXT_PUBLIC_DEEPSEEK_BASE_URL,
      temperature: 0.3,
      maxTokens: 2000,
    });
  }

  private initializeTools() {
    this.tools = [
      new OpLabTool(),
      new DeepSeekAnalysisTool(),
    ];
  }

  async processMessage(message: string, options?: ProcessingOptions) {
    try {
      const result = await this.agent.invoke({
        input: message,
        ...options,
      });

      return {
        response: result.output,
        toolsUsed: result.intermediate_steps,
        cached: false,
      };
    } catch (error) {
      throw new Error(`LangChain processing failed: ${error.message}`);
    }
  }
}
```

### ğŸ”§ OpLab Tool Implementation

```typescript
// src/lib/tools/oplab-tool.ts
import { Tool } from '@langchain/core/tools';

export class OpLabTool extends Tool {
  name = 'oplab_market_data';
  description = 'Busca dados de mercado brasileiro via API OpLab';

  async _call(input: string): Promise<string> {
    try {
      const response = await fetch(`${process.env.OPLAB_BASE_URL}/market`, {
        headers: {
          'Authorization': `Bearer ${process.env.OPLAB_ACCESS_TOKEN}`,
          'Content-Type': 'application/json',
        },
      });

      if (!response.ok) {
        throw new Error(`OpLab API error: ${response.status}`);
      }

      const data = await response.json();
      return JSON.stringify(data);
    } catch (error) {
      return `Erro ao buscar dados da OpLab: ${error.message}`;
    }
  }
}
```

### ğŸ¤– DeepSeek Tool Implementation

```typescript
// src/lib/tools/deepseek-tool.ts
import { Tool } from '@langchain/core/tools';

export class DeepSeekAnalysisTool extends Tool {
  name = 'deepseek_analysis';
  description = 'Realiza anÃ¡lise inteligente usando DeepSeek AI';

  async _call(input: string): Promise<string> {
    try {
      const response = await fetch(`${process.env.NEXT_PUBLIC_DEEPSEEK_BASE_URL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.DEEPSEEK_API_KEY}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'deepseek-chat',
          messages: [
            {
              role: 'user',
              content: input,
            },
          ],
          temperature: 0.3,
          max_tokens: 2000,
        }),
      });

      if (!response.ok) {
        throw new Error(`DeepSeek API error: ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0].message.content;
    } catch (error) {
      return `Erro na anÃ¡lise DeepSeek: ${error.message}`;
    }
  }
}
```

---

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### ğŸ“Š Cache com Redis

```typescript
// src/lib/cache/redis-cache.ts
import Redis from 'ioredis';

export class RedisCacheService {
  private redis: Redis;

  constructor() {
    this.redis = new Redis(process.env.REDIS_URL);
  }

  async get(key: string): Promise<string | null> {
    return await this.redis.get(key);
  }

  async set(key: string, value: string, ttl: number = 300): Promise<void> {
    await this.redis.setex(key, ttl, value);
  }

  generateKey(message: string, userId: string): string {
    return `langchain:${userId}:${Buffer.from(message).toString('base64')}`;
  }
}
```

### ğŸ”„ Retry Logic

```typescript
// src/lib/utils/retry-logic.ts
export async function withRetry<T>(
  fn: () => Promise<T>,
  maxRetries: number = 3,
  delay: number = 1000
): Promise<T> {
  let lastError: Error;

  for (let i = 0; i <= maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error as Error;
      
      if (i === maxRetries) {
        break;
      }

      await new Promise(resolve => setTimeout(resolve, delay * Math.pow(2, i)));
    }
  }

  throw lastError;
}
```

---

## ğŸ“Š Monitoramento e Logs

### ğŸ“ˆ MÃ©tricas de Performance

```typescript
// src/lib/monitoring/metrics.ts
export class LangChainMetrics {
  static trackRequest(userId: string, message: string) {
    console.log('[LANGCHAIN] Request:', {
      userId,
      messageLength: message.length,
      timestamp: new Date().toISOString(),
    });
  }

  static trackResponse(userId: string, responseTime: number, toolsUsed: string[]) {
    console.log('[LANGCHAIN] Response:', {
      userId,
      responseTime,
      toolsUsed,
      timestamp: new Date().toISOString(),
    });
  }

  static trackError(userId: string, error: Error) {
    console.error('[LANGCHAIN] Error:', {
      userId,
      error: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString(),
    });
  }
}
```

---

## ğŸ§ª Testes

### ğŸ”§ Testes UnitÃ¡rios

```typescript
// src/lib/services/__tests__/langchain-integration.test.ts
import { LangChainIntegrationService } from '../langchain-integration';

describe('LangChainIntegrationService', () => {
  let service: LangChainIntegrationService;

  beforeEach(() => {
    service = new LangChainIntegrationService();
  });

  it('should process simple market query', async () => {
    const result = await service.processMessage('/market-status');
    expect(result.response).toBeDefined();
    expect(result.toolsUsed).toContain('oplab_market_data');
  });

  it('should handle DeepSeek analysis', async () => {
    const result = await service.processMessage('Explique covered calls');
    expect(result.response).toBeDefined();
    expect(result.toolsUsed).toContain('deepseek_analysis');
  });
});
```

---

## ğŸš€ PrÃ³ximos Passos

### ğŸ”§ Melhorias TÃ©cnicas

1. **ğŸ¯ OtimizaÃ§Ã£o de Performance**
   - ParalelizaÃ§Ã£o de chamadas
   - Cache mais inteligente
   - Streaming de respostas

2. **ğŸ“Š Monitoramento AvanÃ§ado**
   - MÃ©tricas detalhadas
   - Alertas automÃ¡ticos
   - Dashboard de performance

3. **ğŸ”’ SeguranÃ§a Enhanced**
   - Rate limiting por usuÃ¡rio
   - ValidaÃ§Ã£o de entrada robusta
   - Auditoria de uso

### ğŸ“š DocumentaÃ§Ã£o

- **API Reference**: DocumentaÃ§Ã£o completa da API
- **Tutorial AvanÃ§ado**: Casos de uso complexos
- **Troubleshooting Guide**: SoluÃ§Ã£o de problemas comuns

---

## ğŸ¤ Suporte

### ğŸ“ Contato
- **Issues**: GitHub Issues
- **Documentation**: Esta documentaÃ§Ã£o
- **Community**: Discord/Slack

### ğŸ”— Links Ãšteis
- [LangChain Documentation](https://docs.langchain.com/)
- [DeepSeek API Docs](https://api.deepseek.com/docs)
- [OpLab API Reference](https://api.oplab.com.br/docs)

---

**ğŸ“Š Status:** âœ… **IMPLEMENTADO E FUNCIONANDO** 